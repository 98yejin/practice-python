# Practice Python ğŸ‘©â€ğŸ’»

## Contents

- Datastructures
- Algorithms
- Concurrent Programming
- Python Concurrency and Parallelism Problems
  - Concurrent Web Scraper
  - Parallel File Processing
  - Concurrent Producer-Consumer
- FAQs

## Datastructures

| index | datastructure | link                                 |
| ----- | ------------- | ------------------------------------ |
| 1     | Queue         | [link](/datastructure/_queue.py)     |
| 2     | Hashtable     | [link](/datastructure/hashtable.py)  |
| 3     | Linked list   | [link](/datastructure/linkedlist.py) |
| 4     | Stack         | [link](/datastructure/stack.py)      |
| 5     | Tree          | [link](/datastructure/tree.py)       |
| 6     | Minheap       | [link](/datastructure/minheap.py)    |
| 7     | trie          | [link](/datastructure/trie.py)       |
| 8     | merge sort    | [link](/datastructure/mergesort.py)  |

### Linked Lists

#### Singly Linked List

[Time Complexity]

- Accessing by index : O(m)
- Insertion/Deletion
- Head : O(1)
- Tail : O(n)
- Search: O(n)

[Space Complexity]

- One Node : O(1)
- Overall Node : O(n)

[When to use]

- Stacks, Queues
- Applications where memory efficiency is crucial.
- Situations where only forward traversal is required, such as parsing a linked list of data and processing it sequentially.

#### Doubly Linked List

[Time Complexity]

- Accessing by index : O(m)
- Insertion/Deletion
- Head : O(1)
- Tail : O(1)
- Search: O(n)

[Space Complexity]

- One Node : O(1)
- Overall Node : O(n)

[Why to use]

- Double linked list allow bidirectional traversal, which can be useful in certain scenarios, while single linked lists only support forward traversal.
- But consume more memory per node due to the additional reference to the previous node.

[When to use]

- Queues, deques, and hash tables
- Undo-redo functionality in text editors
- Applications where efficient insertion and deletion operations are required at both ends of the list
- Situations where bidirectional traversal is necessary, such as implementing a cursor in a text editor or navigating through a playlist in a media player

#### Tree

- interview tip : íŠ¸ë¦¬ ë° ê·¸ë˜í”„ ë¬¸ì œë“¤ì€ ëŒ€ë¶€ë¶„ ì„¸ë¶€ì‚¬í•­ì´ ëª¨í˜¸í•˜ê±°ë‚˜ ê°€ì • ìì²´ê°€ í‹€ë¦° ê²½ìš°ê°€ ë§ë‹¤. ìœ ì˜í•˜ê³ , í•„ìš”í•˜ë‹¤ë©´ ëª…í™•í•˜ê²Œ í•´ ì¤„ ê²ƒì„ ìš”êµ¬í•˜ì.

[Traverse binary tree]

- In-order traversal ( `L -> C -> R` )
- Pre-order-traversal ( `C -> L -> R` )
- Post-order traversal ( `L -> R -> C` )

[Min-heap]

- íŠ¸ë¦¬ì˜ ë§ˆì§€ë§‰ ë‹¨ê³„ì—ì„œ ì˜¤ë¥¸ìª½ ë¶€ë¶„ì„ ëº€ ë¶€ë¶„ì´ ê°€ë“ ì±„ì›Œì¡Œë‹¤ëŠ” ì ì´ ì™„ì „ ì´ì§„ íŠ¸ë¦¬
- ê° ë…¸ë“œì˜ ì›ì†Œê°€ ìì‹ë³´ë‹¤ ì‘ë‹¤ëŠ” íŠ¹ì„±ì´ ìˆìŒ
- Insert( `O( logn)` ), extract_min ( `O( logn)` )

[When to use]

- Searching
- Tree operations
- Expression evaluation
- Serialization/deserialization
- Tree visualization

#### Tries

[Time Complexity]

- The time complexity of operations in a Trie depends primarily on the length of the keys and the number of keys stored in the Trie.
- For operations like insertion, search, deletion, and prefix search, the time complexity is typically O(m), where m is the length of the keys involved in the operation.

[When to use]

- í•´ì‹œí…Œì´ë¸”ì„ ì´ìš©í•˜ë©´ ì£¼ì–´ì§„ ë¬¸ìì—´ì´ ìœ íš¨í•œì§€ ì•„ë‹Œì§€ ë¹ ë¥´ê²Œ í™•ì¸í•  ìˆ˜ ìˆì§€ë§Œ, ê·¸ ë¬¸ìì—´ì´ ì–´ë–¤ ìœ íš¨í•œ ë‹¨ì–´ì˜ ì ‘ë‘ì‚¬ì¸ì§€ í™•ì¸í•  ìˆ˜ëŠ” ì—†ë‹¤. íŠ¸ë¼ì´ë¥¼ ì´ìš©í•˜ë©´ ì•„ì£¼ ë¹ ë¥´ê²Œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
- íŠ¸ë¼ì´ëŠ” ê¸¸ì´ê°€ kì¸ ë¬¸ìì—´ì´ ì£¼ì–´ì¡Œì„ ë•Œ O(k) ì‹œê°„ì— í•´ë‹¹ ë¬¸ìì—´ì´ ìœ íš¨í•œ ì ‘ë‘ì‚¬ì¸ì§€ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
- í•´ì‹œí…Œì´ë¸”ì„ ì‚¬ìš©í–ˆì„ ë•Œì™€ ê°™ì€ ìˆ˜í–‰ ì‹œê°„ì´ë‹¤.

[ETC]

- Prefix tree ë¼ê³ ë„ ë¶ˆë¦¬ëŠ” trie
- N-ary tree ì˜ ë³€ì¢…ìœ¼ë¡œ ê° ë…¸ë“œì— ë¬¸ìë¥¼ ì €ì¥í•˜ëŠ” ìë£Œêµ¬ì¡°
- íŠ¸ë¦¬ë¥¼ ì•„ë˜ìª½ìœ¼ë¡œ ìˆœíšŒí•˜ë©´ ë‹¨ì–´ í•˜ë‚˜ê°€ ë‚˜ì˜´
- ë„ ë…¸ë“œë¼ê³  ë¶ˆë¦¬ëŠ” \* ë…¸ë“œëŠ” ì¢…ì¢… ë‹¨ì–´ì˜ ëì„ ë‚˜íƒ€ëƒ„
- ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ ë¬¸ìì—´ íƒìƒ‰ì„ ìœ„í•œ ìë£Œêµ¬ì¡°ë¡œ ë„ë¦¬ ì“°ì„
- ê°ê°ì˜ ë¬¸ì ë‹¨ìœ„ë¡œ ìƒ‰ì¸ì„ êµ¬ì¶•í•œ ê²ƒê³¼ ìœ ì‚¬

#### Graph

- íŠ¸ë¦¬ëŠ” ì‚¬ì´í´ì´ ì—†ëŠ” í•˜ë‚˜ì˜ ì—°ê²° ê·¸ë˜í”„ì„.
- ê·¸ë˜í”„ê°€ íŠ¸ë¦¬ë³´ë‹¤ í° ê°œë…ì„.
- ê·¸ë˜í”„ëŠ” ë‹¨ìˆœíˆ ë…¸ë“œì™€ ê·¸ ë…¸ë“œë¥¼ ì—°ê²°í•˜ëŠ” ê°„ì„ (edge)ì„ í•˜ë‚˜ë¡œ ëª¨ì•„ë†“ì€ ê²ƒì„
- ë°©í–¥ì„±ì´ ìˆì„ ìˆ˜ë„ ìˆê³  ì—†ì„ ìˆ˜ë„ ìˆìŒ.
- ì‚¬ì´í´ì´ ì¡´ì¬í•˜ì§€ ì•Šì„ ìˆ˜ë„ ìˆê³  acycle graph ë¼ê³  ë¶€ë¦„
- ê·¸ë˜í”„ëŠ” ì—¬ëŸ¬ê°œì˜ ê³ ë¦½ëœ ë¶€ë¶„ ê·¸ë˜í”„(isolated subgraphs)ë¡œ êµ¬ì„±ë  ìˆ˜ ìˆê³ , ëª¨ë“  ì •ì  ìŒ(pair of vertices) ê°„ì— ê²½ë¡œê°€ ì¡´ì¬í•˜ëŠ” ê·¸ë˜í”„ëŠ” ì—°ê²° ê·¸ë˜í”„ë¼ê³  ë¶€ë¦„.

[ê·¸ë˜í”„ íƒìƒ‰]

- Depth-first search ( ëª¨ë“  ë…¸ë“œë¥¼ ë°©ë¬¸í•˜ê³ ì í•  ë•Œ ì„ í˜¸ë¨, ë°˜ë“œì‹œ ì–´ë–¤ ë…¸ë“œë¥¼ ë°©ë¬¸í–ˆëŠ”ì§€ ì²´í¬í•´ì•¼í•¨. ì•ˆê·¸ëŸ¬ë©´ ë¬´í•œë£¨í”„ ë¹ ì§€ê¸° ì‰¬ì›€ )
- Breadth-first search ( ìµœë‹¨ ê²½ë¡œ ë˜ëŠ” ì„ì˜ì˜ ê²½ë¡œ, Queue ì‚¬ìš© )

#### Stack

[Time Complexity]

- empty() O(1)
- size(): O(1)
- top(), peek(): O(1)
- push(item): O1
- pop(): O(1)

[Why to use]

- ì¬ê·€ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•  ë•Œ ìœ ìš©í•˜ë‹¤.
- LIFO ìˆœì„œë¥¼ ë”°ë¥¸ë‹¤.
- Suitable when you need to access the most recently added item first or when the order of processing needs to be reversed.

[When to use]

- Function Call Management
- Expression Evaluation
- Undo/Redo Operations
- Backtracking Algorithms ( Depth First Search )
- Parsing Algorithms like XML/HTML

#### Queue

[Time Complexity]

- enqueue(item):O(1)
- dequeue(): O(1)
- peek(): O(1)
- isEmpty(): O(1)

Pythonâ€™s collections.deque

- Copy O(n)
- Append, Append left O(1)
- Pop, Pop left O (1)
- Extend, extend left O(k)
- Rotate O(k)
- Remove O(n)
- Get Length O(1)

[Why to use]

- Suitable when you need to process items in the order they were added or when implementing systems with asynchronous tasks or requests.
- Queues are commonly used in systems with asynchronous tasks or requests, where tasks/requests arrive at irregular intervals and need to be processed in the order they were received. For example, in web servers, incoming HTTP requests are often placed in a queue and processed by worker threads in the order they were received.

[When to use]

- Job Scheduling
- Breadth First Search
- Buffering
- Print Queue Management
- Bounded Buffer

#### Heapq ( priority queue )

[methods]

- heapq.heappush()
- heapq.heappop()
- heapq.heapify()
- heapq.nlargest()
- heapq.nsmallest()

[when to use]

- Heapsort
- Graph Algorithm
  (Dijkstra, Prim, A\*)
- File Compress
- Load Balancing

[ETC]

- Heaps are binary trees for which every parent node has a value less than or equal to any of its children. We refer to this condition as the heap invariant.
- heap[k] <= heap[2*k+1] or heap[k] <= heap[2\*k+2

#### List

[Time Complexity]

- Copy O(n)
- Append O(1)
- Pop Last O(1)
- Pop intermediate O(n)
- Insert O(n)
- Get/Set Item O(1)
- Delete Item O(n)
- Iteration O(n)
- Get Slice O(k)
- Del Slice O(n)
- Set Slice O(k+n)
- Extend O(k)
- Sort O(nlogn)
- Multiply O(nk)
- x in s O(n)
- min(s): O(n)

[When to use]

- Dynamic memory allocation ( scenarios where the size of the data collection is not known in advance )
- Implementing stacks and queues

[Etc]

- ë°°ì—´ì˜ í¬ê¸°ë¥¼ ìë™ìœ¼ë¡œ ì¡°ì ˆí•  ìˆ˜ ìˆìŒ.
- ë°ì´í„°ë¥¼ ë§ë¶™ì¼ ë•Œë§ˆë‹¤ ë°°ì—´ í˜¹ì€ ë¦¬ìŠ¤íŠ¸ì˜ í¬ê¸°ê°€ ì¦ê°€í•¨.
- í•„ìš”ì— ë”°ë¼ í¬ê¸°ë¥¼ ë³€í™”ì‹œí‚¬ ìˆ˜ ìˆìœ¼ë©´ì„œë„ O(1)ì˜ ì ‘ê·¼ ì‹œê°„ì„ ìœ ì§€í•¨. í†µìƒì ìœ¼ë¡œ ë°°ì—´ì´ ê°€ë“ ì°¨ëŠ” ìˆœê°„, ë°°ì—´ì˜ í¬ê¸°ë¥¼ ë‘ ë°°ë¡œ ëŠ˜ë¦¼. í¬ê¸°ë¥¼ ë‘ ë°° ëŠ˜ë¦¬ëŠ” ì‹œê°„ì€ O(n)ì´ì§€ë§Œ ìì£¼ ë°œìƒí•˜ëŠ” ì¼ì´ ì•„ë‹ˆì–´ì„œ amortized insertion time ìœ¼ë¡œ ê³„ì‚°í–ˆì„ ë•ŒëŠ” ì—¬ì „íˆ O(1) ì„

#### Hash Table

[Time Complexity]

- K in d O(1) / O(n)
- Copy O(n) / O(n)
- get item O(1) / O(n)
- Set Item O(1) / O(n)
- Delete item O(1) / O(n)
- Iteration O(n) / O(n)

Avg case times listed for dict objects assume that hash function for the objects is sufficiently robust to make collisions uncommon

[Why to use]

- íš¨ìœ¨ì ì¸ íƒìƒ‰ì„ ìœ„í•œ ìë£Œêµ¬ì¡°
- Linked list ì™€ hash code function ìœ¼ë¡œ êµ¬í˜„í•  ìˆ˜ ìˆìŒ
- ë˜ëŠ” ê· í˜• ì´ì§„ íƒìƒ‰ íŠ¸ë¦¬ë¡œ êµ¬í˜„í•  ìˆ˜ ìˆìŒ. í¬ê¸°ê°€ í° ë°°ì—´ì„ ë¯¸ë¦¬ í• ë‹¹í•´ ë†“ì§€ ì•Šì•„ë„ ë˜ê¸° ë•Œë¬¸ì— ì ì¬ì ìœ¼ë¡œ ì ì€ ê³µê°„ì„ ì‚¬ìš©í•¨.
- í‚¤ì˜ì§‘í•©ì„ íŠ¹ì • ìˆœì„œëŒ€ë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆìŒ

[When to use]

- Storing key-value pairs
- Database indexing
- Caching
- Symbol tables in compilers
- Implementing sets and bags
- Counting frequencies
- Hash-based algorithms

## Algorithms

| index | algorithm     | link                                |
| ----- | ------------- | ----------------------------------- |
| 1     | BFS           | [link](/algorithms/bfs.py)          |
| 2     | DFS           | [link](/algorithms/dfs.py)          |
| 3     | Binary Search | [link](/algorithms/binarysearch.py) |
| 4     | Quick Sort    | [link](/algorithms/quicksort.py)    |

## Concurrent Programming

| index | concurrent programming  | link                                           |
| ----- | ----------------------- | ---------------------------------------------- |
| 1     | barriers                | [link](/concurrent/barriers.py)                |
| 2     | fizzbuzz                | [link](/concurrent/fizzbuzz.py)                |
| 3     | fizzbuzz_async          | [link](/concurrent/fizzbuzz_async.py)          |
| 4     | fizzbuzz_multithreading | [link](/concurrent/fizzbuzz_multithreading.py) |
| 5     | future                  | [link](/concurrent/future.py)                  |
| 6     | helloworld              | [link](/concurrent/helloworld.py)              |
| 7     | interface               | [link](/concurrent/interface.py)               |
| 8     | locks                   | [link](/concurrent/locks.py)                   |
| 9     | quickstart              | [link](/concurrent/quickstart.py)              |
| 10    | semaphores              | [link](/concurrent/semaphores.py)              |
| 11    | sharedresources         | [link](/concurrent/sharedresources.py)         |

## Python Concurrency and Parallelism Problems

### [Concurrent Web Scraper](/crawler/)

- Objective: Implement a concurrent web scraper that retrieves data from
  multiple web pages simultaneously.
- Requirements:
  - Use the requests library to fetch web pages.
  - Utilize the asyncio module to achieve concurrency.
  - Scrape data from a list of URLs concurrently.
  - Process and store the scraped data.
- Extension: Implement rate limiting to avoid overloading the target website.

### [Parallel File Processing](/file_processing/)

- Objective: Develop a program that processes a large set of files concurrently.
- Requirements:
  - Accept a directory path as input.
  - Use the multiprocessing module to process files concurrently.
  - Apply a specific operation to each file (e.g., compression, encryption, or
    analysis).
  - Display the progress and status of the file processing.
- Extension: Implement error handling and logging for file processing failures.

### [Concurrent Producer-Consumer](/producer_consumer/)

- Objective: Implement a concurrent producer-consumer system using threads.
- Requirements:
  - Create a shared queue to store data items.
  - Implement producer threads that generate and add data items to the queue.
  - Implement consumer threads that retrieve and process data items from the
    queue.
  - Use synchronization primitives (e.g., locks or semaphores) to ensure thread
    safety.
  - Display the production and consumption of data items.
- Extension: Implement a mechanism to gracefully terminate the producer and
  consumer threads.

## FAQs
